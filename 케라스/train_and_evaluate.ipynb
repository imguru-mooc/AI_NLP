{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb291b62b1aa"
   },
   "source": [
    "# Training and evaluation with the built-in methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d4ac441b1fc"
   },
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:48.305955Z",
     "iopub.status.busy": "2021-04-07T17:58:48.305368Z",
     "iopub.status.idle": "2021-04-07T17:58:53.785129Z",
     "shell.execute_reply": "2021-04-07T17:58:53.785508Z"
    },
    "id": "0472bf67b2bf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c16fe7fd6a6c"
   },
   "source": [
    "## 시작하기\n",
    "\n",
    "이 안내서는 훈련 및 유효성 검증을 위해 내장 API를 사용할 때의 훈련, 평가 및 예측 (추론) 모델 (예 : `model.fit()` , `model.evaluate()` , `model.predict()` )에 대해 설명합니다.\n",
    "\n",
    "고유한 훈련 단계 함수를 지정하면서 `fit()`을 사용하려면 <a href=\"https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\" data-md-type=\"link\">\" `fit()`에서 이루어지는 작업 사용자 정의하기\"</a> 가이드를 참조하세요.\n",
    "\n",
    "고유한 훈련 및 평가 루프를 처음부터 작성하려면 [\"처음부터 훈련 루프 작성\"](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/) 안내서를 참조하십시오.\n",
    "\n",
    "일반적으로, 내장 루프를 사용하든 직접 작성하든 관계없이 모델 훈련 및 유효성 검사는 모든 종류의 Keras 모델(순차 모델, Functional API로 작성된 모델 및 모델 하위 클래스화를 통해 처음부터 작성된 모델)에서 완전히 동일하게 작동합니다.\n",
    "\n",
    "이 가이드는 분산 교육에 대해서는 다루지 않습니다. 분산 교육에 대해서는 [멀티 GPU 및 분산 교육 안내서를](https://keras.io/guides/distributed_training/) 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e270faa413e"
   },
   "source": [
    "## API 개요 : 첫 번째 엔드 투 엔드 예제\n",
    "\n",
    "데이터를 모델의 내장 훈련 루프로 전달할 때는 **NumPy 배열**(데이터가 작고 메모리에 맞는 경우) 또는 **`tf.data Dataset` 객체**를 사용해야 합니다. 다음 몇 단락에서는 옵티마이저, 손실 및 메트릭을 사용하는 방법을 보여주기 위해 MNIST 데이터세트를 NumPy 배열로 사용하겠습니다.\n",
    "\n",
    "다음 모델을 고려해 보겠습니다 (여기서는 Functional API를 사용하여 빌드하지만 Sequential 모델 또는 하위 클래스 모델 일 수도 있음)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:53.792832Z",
     "iopub.status.busy": "2021-04-07T17:58:53.792213Z",
     "iopub.status.idle": "2021-04-07T17:58:55.407575Z",
     "shell.execute_reply": "2021-04-07T17:58:55.408010Z"
    },
    "id": "170a6a18b2a3"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")    \n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)          # (None,784)(784,64)+(64,)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)               # (None,64)(64,64)+(64,)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x) # (None,64)(64,10)+(10,)\n",
    "                                                                        # (None,10)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6d5724a90ab"
   },
   "source": [
    "일반적인 엔드 투 엔드 워크 플로는 다음과 같이 구성되어 있습니다.\n",
    "\n",
    "- 학습\n",
    "- 원래 교육 데이터에서 생성 된 홀드 아웃 세트에 대한 유효성 검사\n",
    "- 테스트 데이터에 대한 평가\n",
    "\n",
    "이 예에서는 MNIST 데이터를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.413652Z",
     "iopub.status.busy": "2021-04-07T17:58:55.413065Z",
     "iopub.status.idle": "2021-04-07T17:58:55.758213Z",
     "shell.execute_reply": "2021-04-07T17:58:55.757663Z"
    },
    "id": "8b55b3903edb"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77a84eb1985b"
   },
   "source": [
    "훈련 구성(최적화 프로그램, 손실, 메트릭)을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.769921Z",
     "iopub.status.busy": "2021-04-07T17:58:55.769317Z",
     "iopub.status.idle": "2021-04-07T17:58:55.788128Z",
     "shell.execute_reply": "2021-04-07T17:58:55.787601Z"
    },
    "id": "26a7f1819796"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef28150b1eaa"
   },
   "source": [
    "`fit()`를 호출하여 데이터를 \"batch_size\" 크기의 \"배치\"로 분할하고 지정된 수의 \"epoch\"에 대해 전체 데이터세트를 반복 처리하여 모델을 훈련시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.792862Z",
     "iopub.status.busy": "2021-04-07T17:58:55.792230Z",
     "iopub.status.idle": "2021-04-07T17:59:00.616809Z",
     "shell.execute_reply": "2021-04-07T17:59:00.617243Z"
    },
    "id": "0b92f67b105e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3523 - sparse_categorical_accuracy: 0.9020 - val_loss: 0.1747 - val_sparse_categorical_accuracy: 0.9514\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 1s 920us/step - loss: 0.1614 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.1277 - val_sparse_categorical_accuracy: 0.9631\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a1b698c6e39"
   },
   "source": [
    "반환되는 \"이력\" 객체는 훈련 중 손실 값과 메트릭 값에 대한 레코드를 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.625752Z",
     "iopub.status.busy": "2021-04-07T17:59:00.625141Z",
     "iopub.status.idle": "2021-04-07T17:59:00.628091Z",
     "shell.execute_reply": "2021-04-07T17:59:00.628463Z"
    },
    "id": "a20b8f5b9fcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3522537052631378, 0.16135941445827484],\n",
       " 'sparse_categorical_accuracy': [0.9020400047302246, 0.95278000831604],\n",
       " 'val_loss': [0.17473295331001282, 0.12767688930034637],\n",
       " 'val_sparse_categorical_accuracy': [0.9513999819755554, 0.963100016117096]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6105b646df66"
   },
   "source": [
    "`evaluate()`를 통해 테스트 데이터에 대해 모델을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.632994Z",
     "iopub.status.busy": "2021-04-07T17:59:00.632410Z",
     "iopub.status.idle": "2021-04-07T17:59:00.894621Z",
     "shell.execute_reply": "2021-04-07T17:59:00.894161Z"
    },
    "id": "69f524a93f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 613us/step - loss: 0.1327 - sparse_categorical_accuracy: 0.9601\n",
      "test loss, test acc: [0.13269327580928802, 0.960099995136261]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (3, 10)\n",
      "[[8.8633806e-06 9.2873250e-08 2.3185459e-04 1.8675232e-03 6.7191492e-09\n",
      "  1.0400959e-06 1.5130620e-10 9.9763560e-01 6.2129061e-07 2.5433931e-04]\n",
      " [1.3048852e-06 1.2589873e-04 9.9951959e-01 3.4140088e-04 7.4243786e-14\n",
      "  4.6723903e-06 6.2971335e-06 1.2707081e-08 8.4677367e-07 1.0721250e-12]\n",
      " [3.4637735e-06 9.9432147e-01 6.5529835e-04 3.0501303e-04 1.6607929e-04\n",
      "  2.7171843e-04 2.3159002e-04 2.6578605e-03 1.1148755e-03 2.7271375e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f19d074eb88c"
   },
   "source": [
    "이제이 워크 플로의 각 부분을 자세히 검토하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3669f026d14"
   },
   "source": [
    "## `compile()` 메소드 : 손실, 메트릭 및 최적화 프로그램 지정\n",
    "\n",
    "`fit()` 으로 모델을 학습하려면 손실 함수, 최적화 프로그램 및 선택적으로 모니터링 할 일부 메트릭을 지정해야합니다.\n",
    "\n",
    "이것을 `compile()` 메소드의 인수로 모델에 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.903471Z",
     "iopub.status.busy": "2021-04-07T17:59:00.902774Z",
     "iopub.status.idle": "2021-04-07T17:59:00.912104Z",
     "shell.execute_reply": "2021-04-07T17:59:00.911681Z"
    },
    "id": "eb7a8deb494c"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4061c977ac3"
   },
   "source": [
    "`metrics` 인수는 목록이어야합니다. 모델에는 여러 개의 메트릭이있을 수 있습니다.\n",
    "\n",
    "모델에 여러 개의 출력이있는 경우 각 출력에 대해 서로 다른 손실 및 메트릭을 지정하고 모델의 총 손실에 대한 각 출력의 기여도를 조정할 수 있습니다. 이에 대한 자세한 내용은 **\"다중 입력, 다중 출력 모델로 데이터 전달\"** 섹션에서 확인할 수 있습니다.\n",
    "\n",
    "기본 설정에 만족하면 대부분의 경우 최적화, 손실 및 메트릭을 문자열 식별자를 통해 바로 가기로 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.920513Z",
     "iopub.status.busy": "2021-04-07T17:59:00.919946Z",
     "iopub.status.idle": "2021-04-07T17:59:00.924629Z",
     "shell.execute_reply": "2021-04-07T17:59:00.924967Z"
    },
    "id": "6444839ff300"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5493ab963254"
   },
   "source": [
    "나중에 재사용하기 위해 모델 정의와 컴파일 단계를 함수에 넣겠습니다. 이 안내서의 여러 예에서 여러 번 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.930518Z",
     "iopub.status.busy": "2021-04-07T17:59:00.929926Z",
     "iopub.status.idle": "2021-04-07T17:59:00.932021Z",
     "shell.execute_reply": "2021-04-07T17:59:00.931520Z"
    },
    "id": "31c3e3c70f06"
   },
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21b19c0a6a85"
   },
   "source": [
    "### 많은 내장 옵티 마이저, 손실 및 메트릭을 사용할 수 있습니다\n",
    "\n",
    "일반적으로 고유한 손실, 메트릭 또는 최적화 프로그램을 처음부터 새로 만들 필요가 없는데, Keras API에 필요한 것들이 이미 들어 있을 개연성이 높기 때문입니다.\n",
    "\n",
    "옵티마이저\n",
    "\n",
    "- `SGD()` (모멘텀이 있거나 없음)\n",
    "- `RMSprop()`\n",
    "- `Adam()`\n",
    "- 기타\n",
    "\n",
    "손실:\n",
    "\n",
    "- `MeanSquaredError()`\n",
    "- `KLDivergence()`\n",
    "- `CosineSimilarity()`\n",
    "- 기타\n",
    "\n",
    "메트릭\n",
    "\n",
    "- `AUC()`\n",
    "- `Precision()`\n",
    "- `Recall()`\n",
    "- 기타"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7abc0339980"
   },
   "source": [
    "### 관례 손실\n",
    "\n",
    "Keras로 커스텀 손실을 제공하는 두 가지 방법이 있습니다. 첫 번째 예는 입력 `y_true` 및 `y_pred` 를 받아들이는 함수를 만듭니다. 다음 예는 실제 데이터와 예측 간의 평균 제곱 오차를 계산하는 손실 함수를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.938634Z",
     "iopub.status.busy": "2021-04-07T17:59:00.938085Z",
     "iopub.status.idle": "2021-04-07T17:59:02.545087Z",
     "shell.execute_reply": "2021-04-07T17:59:02.544610Z"
    },
    "id": "cc4edd47bb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 750us/step - loss: 0.0161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20bd77abdc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_mean_squared_error(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)\n",
    "\n",
    "# We need to one-hot encode the labels to use MSE\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25b9fa7941ca"
   },
   "source": [
    "`y_true` 및 `y_pred` 이외의 매개 변수를 사용하는 손실 함수가 필요한 경우 `tf.keras.losses.Loss` 클래스를 서브 클래스 화하고 다음 두 메소드를 구현할 수 있습니다.\n",
    "\n",
    "- `__init__(self)` : 손실 함수 호출 중에 전달할 매개 변수를 승인합니다.\n",
    "- `call(self, y_true, y_pred)` : 목표 (y_true)와 모델 예측 (y_pred)을 사용하여 모델의 손실을 계산\n",
    "\n",
    "평균 제곱 오차를 사용하려고하지만 예측 값을 0.5에서 멀어지게하는 용어가 추가되었다고 가정 해 보겠습니다 (우리는 범주 형 목표가 원-핫 인코딩되고 0과 1 사이의 값을 취하는 것으로 가정). 이렇게하면 모델이 너무 자신감이없는 인센티브가 생겨 과적 합을 줄이는 데 도움이 될 수 있습니다 (시도 할 때까지 작동하는지 알 수 없음).\n",
    "\n",
    "방법은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:02.553096Z",
     "iopub.status.busy": "2021-04-07T17:59:02.552526Z",
     "iopub.status.idle": "2021-04-07T17:59:04.353462Z",
     "shell.execute_reply": "2021-04-07T17:59:04.353833Z"
    },
    "id": "b09463a8c568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 771us/step - loss: 0.0392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20bdbd27ee0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
    "        return mse + reg * self.regularization_factor\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2141cc075a6"
   },
   "source": [
    "### 맞춤 측정 항목\n",
    "\n",
    "API의 일부가 아닌 메트릭이 필요한 경우 `tf.keras.metrics.Metric` 클래스를 서브 클래 싱하여 사용자 지정 메트릭을 쉽게 만들 수 있습니다. 4 가지 방법을 구현해야합니다.\n",
    "\n",
    "- `__init__(self)` . 여기서 메트릭에 대한 상태 변수를 만듭니다.\n",
    "- `update_state(self, y_true, y_pred, sample_weight=None)` 대상 y_true 및 모델 예측 y_pred를 사용하여 상태 변수를 업데이트합니다.\n",
    "- `result(self)` : 상태 변수를 사용하여 최종 결과를 계산합니다.\n",
    "- `reset_states(self)` : 메트릭의 상태를 다시 초기화합니다.\n",
    "\n",
    "경우에 따라 결과 계산이 매우 비싸고 주기적으로 만 수행되기 때문에 상태 업데이트와 결과 계산은 각각 `update_state()` 와 `result()` 에서 별도로 유지됩니다.\n",
    "\n",
    "다음은 `CategoricalTruePositives` 메트릭을 구현하는 방법을 보여주는 간단한 예제입니다.이 메트릭은 주어진 클래스에 속하는 것으로 올바르게 분류 된 샘플 수를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:04.363314Z",
     "iopub.status.busy": "2021-04-07T17:59:04.362654Z",
     "iopub.status.idle": "2021-04-07T17:59:09.979834Z",
     "shell.execute_reply": "2021-04-07T17:59:09.980190Z"
    },
    "id": "05d6a6e7022d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 1s 758us/step - loss: 0.3428 - categorical_true_positives: 0.0000e+00\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 790us/step - loss: 0.1664 - categorical_true_positives: 0.0000e+00\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 791us/step - loss: 0.1190 - categorical_true_positives: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20be145cbe0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "        self.flag = 0\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         print(\"update_state()\")\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1)) # [0.1,0.2,0.5,0.1,0.1]=>(N,C)=>(N,1)\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\") # [True,False,True,False,True,False...]\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        \n",
    "        if self.flag == 0 :\n",
    "            self.true_positives.assign_add(tf.reduce_sum(values))  #self.true_positives += 55\n",
    "            self.flag = 1\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    def reset_state(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.true_positives.assign(0.0)\n",
    "        self.flag == 0\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[CategoricalTruePositives()],\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bca8e959cda"
   },
   "source": [
    "### 표준 서명에 맞지 않는 손실 및 메트릭 처리하기\n",
    "\n",
    "거의 대부분의 손실과 메트릭은 `y_true` 및 `y_pred`에서 계산할 수 있습니다(여기서 `y_pred`가 모델의 출력). 그러나 모두가 그런 것은 아닙니다. 예를 들어, 정규화 손실은 레이어의 활성화만 요구할 수 있으며(이 경우 대상이 없음) 이 활성화는 모델 출력이 아닐 수 있습니다.\n",
    "\n",
    "이러한 경우 사용자 정의 레이어의 호출 메서드 내에서 `self.add_loss(loss_value)`를 호출할 수 있습니다. 이러한 방식으로 추가된 손실은 훈련 중 \"주요\" 손실(`compile()`로 전달되는 손실)에 추가됩니다. 다음은 활동 정규화를 추가하는 간단한 예입니다. 참고로 활동 정규화는 모든 Keras 레이어에 내장되어 있으며 이 레이어는 구체적인 예를 제공하기 위한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:09.989008Z",
     "iopub.status.busy": "2021-04-07T17:59:09.988416Z",
     "iopub.status.idle": "2021-04-07T17:59:12.011691Z",
     "shell.execute_reply": "2021-04-07T17:59:12.011174Z"
    },
    "id": "b494d47437a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 809us/step - loss: 2.5275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20be24ed490>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)  # (None,784)(784,64)\n",
    "\n",
    "# Insert activity regularization as a layer\n",
    "x = ActivityRegularizationLayer()(x)       # (None,64) => (None,64)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# The displayed loss will be much higher than before\n",
    "# due to the regularization component.\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaebb5829011"
   },
   "source": [
    "`add_metric()` 사용하여 메트릭 값 로깅에 대해 동일한 작업을 수행 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:12.021377Z",
     "iopub.status.busy": "2021-04-07T17:59:12.019956Z",
     "iopub.status.idle": "2021-04-07T17:59:14.167067Z",
     "shell.execute_reply": "2021-04-07T17:59:14.167421Z"
    },
    "id": "aa58091be092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 826us/step - loss: 0.3519 - std_of_activation: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20be57f3cd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MetricLoggingLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # The `aggregation` argument defines\n",
    "        # how to aggregate the per-batch values\n",
    "        # over each epoch:\n",
    "        # in this case we simply average them.\n",
    "        self.add_metric(\n",
    "            keras.backend.std(inputs), name=\"std_of_activation\", aggregation=\"mean\"\n",
    "        )\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert std logging as a layer.\n",
    "x = MetricLoggingLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3c18154d057"
   },
   "source": [
    "[Functional API](https://www.tensorflow.org/guide/keras/functional/) 에서 `model.add_loss(loss_tensor)` 또는 `model.add_metric(metric_tensor, name, aggregation)` 호출 할 수도 있습니다.\n",
    "\n",
    "다음은 간단한 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:14.176154Z",
     "iopub.status.busy": "2021-04-07T17:59:14.175268Z",
     "iopub.status.idle": "2021-04-07T17:59:16.355388Z",
     "shell.execute_reply": "2021-04-07T17:59:16.354905Z"
    },
    "id": "0e19afe78b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 831us/step - loss: 2.4974 - std_of_activation: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20be6d8d700>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b06d48035369"
   },
   "source": [
    "`add_loss()` 를 통해 손실을 전달하면 모델에는 이미 손실이 있으므로 손실 함수없이 `compile()` 을 호출 할 수 있습니다.\n",
    "\n",
    "다음 `LogisticEndpoint` 레이어를 생각해 보겠습니다. 이 레이어는 입력으로 targets 및 logits를 받아들이고 `add_loss()`를 통해 교차 엔트로피 손실을 추적합니다. 또한 `add_metric()`를 통해 분류 정확도도 추적합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.361776Z",
     "iopub.status.busy": "2021-04-07T17:59:16.361194Z",
     "iopub.status.idle": "2021-04-07T17:59:16.362990Z",
     "shell.execute_reply": "2021-04-07T17:59:16.363332Z"
    },
    "id": "d56d2c504258"
   },
   "outputs": [],
   "source": [
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Log accuracy as a metric and add it\n",
    "        # to the layer using `self.add_metric()`.\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "\n",
    "        # Return the inference-time prediction tensor (for `.predict()`).\n",
    "        return tf.nn.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0698f3c98cbe"
   },
   "source": [
    "다음과 같이 `loss` 인수없이 컴파일 된 두 개의 입력 (입력 데이터 및 대상)이있는 모델에서 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.372039Z",
     "iopub.status.busy": "2021-04-07T17:59:16.370993Z",
     "iopub.status.idle": "2021-04-07T17:59:16.746912Z",
     "shell.execute_reply": "2021-04-07T17:59:16.747257Z"
    },
    "id": "0f6842f2bbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 787 calls to <function Model.make_train_function.<locals>.train_function at 0x0000020BE725F0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.9542 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20be7185100>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
    "targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "logits = keras.layers.Dense(10)(inputs)\n",
    "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n",
    "\n",
    "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "model.compile(optimizer=\"adam\")  # No loss argument!\n",
    "\n",
    "data = {\n",
    "    \"inputs\": np.random.random((3, 3)),\n",
    "    \"targets\": np.random.random((3, 10)),\n",
    "}\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "328b021aa6b8"
   },
   "source": [
    "다중 입력 모델 교육에 대한 자세한 내용은 **다중 입력, 다중 출력 모델로 데이터 전달** 섹션을 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0536882b969c"
   },
   "source": [
    "### 유효성 검사 홀드아웃 세트를 자동으로 분리하기\n",
    "\n",
    "본 첫 번째 엔드 투 엔드 예제에서, 우리는 `validation_data` 인수를 사용하여 NumPy 배열의 튜플 `(x_val, y_val)` 을 모델에 전달하여 각 에포크의 끝에서 유효성 검증 손실 및 유효성 검증 메트릭을 평가합니다.\n",
    "\n",
    "또 다른 옵션: 인수 `validation_split`를 사용하여 유효성 검사 목적으로 훈련 데이터의 일부를 자동으로 예약할 수 있습니다. 인수 값은 유효성 검사를 위해 예약할 데이터 비율을 나타내므로 0보다 크고 1보다 작은 값으로 설정해야 합니다. 예를 들어, `validation_split=0.2`는 \"유효성 검사를 위해 데이터의 20%를 사용\"한다는 의미이고`validation_split=0.6`은 \"유효성 검사를 위해 데이터의 60%를 사용\"한다는 의미입니다.\n",
    "\n",
    "유효성을 계산하는 방법은 셔플 링 전에 맞춤 호출로 수신 한 배열의 마지막 x % 샘플을 가져 오는 것입니다.\n",
    "\n",
    "NumPy 데이터를 학습 할 때 `validation_split` 만 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.754009Z",
     "iopub.status.busy": "2021-04-07T17:59:16.753094Z",
     "iopub.status.idle": "2021-04-07T17:59:18.729991Z",
     "shell.execute_reply": "2021-04-07T17:59:18.729293Z"
    },
    "id": "232fd59c751b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step - loss: 0.3674 - sparse_categorical_accuracy: 0.8952 - val_loss: 0.2336 - val_sparse_categorical_accuracy: 0.9316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20bf5635e20>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42969af7ce01"
   },
   "source": [
    "## tf.data 데이터 세트의 교육 및 평가\n",
    "\n",
    "앞서 몇 단락에 걸쳐 손실, 메트릭 및 옵티마이저를 처리하는 방법을 살펴보았으며, 데이터가 NumPy 배열로 전달될 때 fit에서 `validation_data` 및 `validation_split` 인수를 사용하는 방법도 알아보았습니다.\n",
    "\n",
    "이제 데이터가 `tf.data.Dataset` 객체의 형태로 제공되는 경우를 살펴 보겠습니다.\n",
    "\n",
    "`tf.data` API는 빠르고 확장 가능한 방식으로 데이터를 로드하고 사전 처리하기 위한 TensorFlow 2.0의 유틸리티 세트입니다.\n",
    "\n",
    "`Datasets` 생성에 대한 자세한 설명은 [tf.data 설명서](https://www.tensorflow.org/guide/data)를 참조하세요.\n",
    "\n",
    "`Dataset` 인스턴스를 메서드 `fit()`, `evaluate()` 및 `predict()`로 직접 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "(64, 784)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "for data in train_dataset.take(1):\n",
    "    print(data[0].shape)\n",
    "    print(data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:18.737374Z",
     "iopub.status.busy": "2021-04-07T17:59:18.736671Z",
     "iopub.status.idle": "2021-04-07T17:59:25.389166Z",
     "shell.execute_reply": "2021-04-07T17:59:25.388563Z"
    },
    "id": "3bf4ded224f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 1s 969us/step - loss: 0.3374 - sparse_categorical_accuracy: 0.9050\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 1s 973us/step - loss: 0.1543 - sparse_categorical_accuracy: 0.9548\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 1s 956us/step - loss: 0.1133 - sparse_categorical_accuracy: 0.9664\n",
      "Evaluate\n",
      "157/157 [==============================] - 0s 714us/step - loss: 0.1146 - sparse_categorical_accuracy: 0.9653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.11459561437368393,\n",
       " 'sparse_categorical_accuracy': 0.9653000235557556}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# First, let's create a training Dataset instance.\n",
    "# For the sake of our example, we'll use the same MNIST data as before.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Now we get a test dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Since the dataset already takes care of batching,\n",
    "# we don't pass a `batch_size` argument.\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "421d16914ce3"
   },
   "source": [
    "데이터세트는 각 epoch의 끝에서 재설정되므로 다음 epoch에서 재사용할 수 있습니다.\n",
    "\n",
    "이 데이터세트의 특정 배치 수에 대해서만 훈련을 실행하려면 다음 epoch로 이동하기 전에 이 데이터세트를 사용하여 모델이 실행해야 하는 훈련 단계의 수를 지정하는 `steps_per_epoch` 인수를 전달할 수 있습니다.\n",
    "\n",
    "이렇게 하면 각 epoch가 끝날 때 데이터세트가 재설정되지 않고 다음 배치를 계속 가져오게 됩니다. 무한 반복되는 데이터세트가 아니라면 결국 데이터세트의 데이터가 고갈됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:25.395575Z",
     "iopub.status.busy": "2021-04-07T17:59:25.394783Z",
     "iopub.status.idle": "2021-04-07T17:59:26.675941Z",
     "shell.execute_reply": "2021-04-07T17:59:26.675448Z"
    },
    "id": "273c5dff16b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 0s 898us/step - loss: 0.7914 - sparse_categorical_accuracy: 0.7947\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 914us/step - loss: 0.3722 - sparse_categorical_accuracy: 0.8913\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 898us/step - loss: 0.3212 - sparse_categorical_accuracy: 0.9034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20bf688de50>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "model.fit(train_dataset, epochs=3, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2dcd180da7b"
   },
   "source": [
    "### 유효성 검사 데이터 집합 사용\n",
    "\n",
    "`fit()` 에서 `Dataset` 인스턴스를 `validation_data` 인수로 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:26.682749Z",
     "iopub.status.busy": "2021-04-07T17:59:26.681981Z",
     "iopub.status.idle": "2021-04-07T17:59:29.751000Z",
     "shell.execute_reply": "2021-04-07T17:59:29.751364Z"
    },
    "id": "bf4f3d78e69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3454 - sparse_categorical_accuracy: 0.9029 - val_loss: 0.2129 - val_sparse_categorical_accuracy: 0.9382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b800f3a60>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e7f0ebf5f1d"
   },
   "source": [
    "각 시대가 끝날 때 모델은 유효성 검사 데이터 집합을 반복하고 유효성 검사 손실 및 유효성 검사 메트릭을 계산합니다.\n",
    "\n",
    "이 데이터세트의 특정 배치 수에 대해서만 유효성 검사를 실행하려면 유효성 검사를 중단하고 다음 epoch로 넘어가기 전에 유효성 검사 데이터세트에서 모델이 실행해야 하는 유효성 검사 단계의 수를 지정하는 `validation_steps` 인수를 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:29.758316Z",
     "iopub.status.busy": "2021-04-07T17:59:29.757458Z",
     "iopub.status.idle": "2021-04-07T17:59:32.372341Z",
     "shell.execute_reply": "2021-04-07T17:59:32.372720Z"
    },
    "id": "f47342fed069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.3437 - sparse_categorical_accuracy: 0.9032 - val_loss: 0.3059 - val_sparse_categorical_accuracy: 0.9250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b800f3a00>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,\n",
    "    # Only run validation using the first 10 batches of the dataset\n",
    "    # using the `validation_steps` argument\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67b4418e9f26"
   },
   "source": [
    "유효성 검사 데이터 세트는 사용 후마다 재설정되므로 항상 에포크에서 에포크까지 동일한 샘플을 평가하게됩니다.\n",
    "\n",
    "인수 `validation_split`(훈련 데이터로부터 홀드아웃 세트 생성)는 `Dataset` 객체로 훈련할 때는 지원되지 않는데, 이를 위해서는 데이터세트 샘플을 인덱싱할 수 있어야 하지만 `Dataset` API에서는 일반적으로 이것이 불가능하기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8160beb766a0"
   },
   "source": [
    "## 지원되는 다른 입력 형식\n",
    "\n",
    "NumPy 배열, 즉시 실행 텐서 및 TensorFlow `Datasets` 외에도 Pandas 데이터프레임을 사용하거나 데이터 및 레이블의 배치를 생성하는 Python 생성기에서 Keras 모델을 훈련할 수 있습니다.\n",
    "\n",
    "특히, `keras.utils.Sequence` 클래스는 멀티스레딩을 인식하고 셔플이 가능한 Python 데이터 생성기를 빌드하기 위한 간단한 인터페이스를 제공합니다.\n",
    "\n",
    "일반적으로 다음을 사용하는 것이 좋습니다.\n",
    "\n",
    "- 데이터가 작고 메모리에 맞는 경우 NumPy 입력 데이터\n",
    "- 큰 데이터세트가 있고 분산 훈련을 수행해야 하는 경우 `Dataset` 객체\n",
    "- 큰 데이터세트가 있고 TensorFlow에서 수행할 수 없는 많은 사용자 정의 Python 측 처리를 수행해야 하는 경우(예: 데이터 로드 또는 사전 처리를 위해 외부 라이브러리에 의존하는 경우) `Sequence` 객체\n",
    "\n",
    "## `keras.utils.Sequence` 객체를 입력으로 사용하기\n",
    "\n",
    "`keras.utils.Sequence`는 두 가지 중요한 속성을 가진 Python 생성기를 얻기 위해 하위 클래스화를 수행할 수 있는 유틸리티입니다.\n",
    "\n",
    "- 멀티 프로세싱과 잘 작동합니다.\n",
    "- 셔플할 수 있습니다(예: `fit()`에서 `shuffle=True`를 전달하는 경우).\n",
    "\n",
    "`Sequence` 는 두 가지 방법을 구현해야합니다.\n",
    "\n",
    "- `__getitem__`\n",
    "- `__len__`\n",
    "\n",
    "`__getitem__` 메소드는 완전한 배치를 리턴해야합니다. 신기원 사이의 데이터 세트를 수정하려면 `on_epoch_end` 구현할 수 있습니다.\n",
    "\n",
    "간단한 예를 들자면 다음과 같습니다.\n",
    "\n",
    "```python\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "# Here, `filenames` is list of path to the images\n",
    "# and `labels` are the associated labels.\n",
    "\n",
    "class CIFAR10Sequence(Sequence):\n",
    "    def __init__(self, filenames, labels, batch_size):\n",
    "        self.filenames, self.labels = filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([\n",
    "            resize(imread(filename), (200, 200))\n",
    "               for filename in batch_x]), np.array(batch_y)\n",
    "\n",
    "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
    "model.fit(sequence, epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a28343b1967"
   },
   "source": [
    "## 샘플 가중치 및 클래스 가중치 사용\n",
    "\n",
    "기본 설정을 사용하면 샘플의 무게가 데이터 세트의 빈도에 따라 결정됩니다. 샘플 빈도와 관계없이 데이터에 가중치를 부여하는 방법에는 두 가지가 있습니다.\n",
    "\n",
    "- 클래스 가중치\n",
    "- 샘플 무게"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f234a9a75b6d"
   },
   "source": [
    "### 클래스 가중치\n",
    "\n",
    "이 가중치는 `Model.fit()`에 대한 `class_weight` 인수로 사전을 전달하여 설정합니다. 이 사전은 클래스 인덱스를 이 클래스에 속한 샘플에 사용해야 하는 가중치에 매핑합니다.\n",
    "\n",
    "이 방법은 샘플링을 다시 수행하지 않고 클래스의 균형을 맞추거나 특정 클래스에 더 중요한 모델을 훈련시키는 데 사용할 수 있습니다.\n",
    "\n",
    "예를 들어, 데이터에서 클래스 \"0\"이 클래스 \"1\"로 표시된 것의 절반인 경우 `Model.fit(..., class_weight={0: 1., 1: 0.5})`을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9929d26d91b8"
   },
   "source": [
    "다음은 클래스 #5(MNIST 데이터세트에서 숫자 \"5\")의 올바른 분류에 더 많은 중요성을 두도록 클래스 가중치 또는 샘플 가중치를 사용하는 NumPy 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:32.379985Z",
     "iopub.status.busy": "2021-04-07T17:59:32.379268Z",
     "iopub.status.idle": "2021-04-07T17:59:34.552093Z",
     "shell.execute_reply": "2021-04-07T17:59:34.552450Z"
    },
    "id": "f1844f2329a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with class weight\n",
      "782/782 [==============================] - 1s 881us/step - loss: 0.3895 - sparse_categorical_accuracy: 0.8978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b8132b9a0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: 1.0,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    # Set weight \"2\" for class \"5\",\n",
    "    # making this class 2x more important\n",
    "    5: 2.0,\n",
    "    6: 1.0,\n",
    "    7: 1.0,\n",
    "    8: 1.0,\n",
    "    9: 1.0,\n",
    "}\n",
    "\n",
    "print(\"Fit with class weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce27221fad08"
   },
   "source": [
    "### 샘플 무게\n",
    "\n",
    "세밀한 제어를 위해 또는 분류기를 작성하지 않는 경우 \"샘플 가중치\"를 사용할 수 있습니다.\n",
    "\n",
    "- NumPy 데이터에서 학습하는 경우 : `sample_weight` 인수를 `Model.fit()` .\n",
    "- `tf.data` 또는 다른 종류의 반복자에서 훈련 할 때 : Yield `(input_batch, label_batch, sample_weight_batch)` 튜플.\n",
    "\n",
    "\"샘플 가중치\"배열은 배치에서 각 샘플이 총 손실을 계산하는 데 필요한 가중치를 지정하는 숫자 배열입니다. 불균형 분류 문제 (거의 보이지 않는 클래스에 더 많은 가중치를 부여하는 아이디어)에 일반적으로 사용됩니다.\n",
    "\n",
    "사용 된 가중치가 1과 0 인 경우, 어레이는 손실 함수에 대한 *마스크* 로 사용될 수 있습니다 (전체 손실에 대한 특정 샘플의 기여를 완전히 버림)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:34.557087Z",
     "iopub.status.busy": "2021-04-07T17:59:34.556528Z",
     "iopub.status.idle": "2021-04-07T17:59:41.179312Z",
     "shell.execute_reply": "2021-04-07T17:59:41.178824Z"
    },
    "id": "f9819d647793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with sample weight\n",
      "782/782 [==============================] - 1s 847us/step - loss: 0.3757 - sparse_categorical_accuracy: 0.9019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b8241d9a0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "print(\"Fit with sample weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[[0,5,9]] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:41.184161Z",
     "iopub.status.busy": "2021-04-07T17:59:41.183589Z",
     "iopub.status.idle": "2021-04-07T17:59:43.788537Z",
     "shell.execute_reply": "2021-04-07T17:59:43.788025Z"
    },
    "id": "c870f3f0c66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 996us/step - loss: 0.3626 - sparse_categorical_accuracy: 0.9053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b82534f40>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "# Create a Dataset that includes sample weights\n",
    "# (3rd element in the return tuple).\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
    "\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3963bfa348b0"
   },
   "source": [
    "## 다중 입력, 다중 출력 모델로 데이터 전달\n",
    "\n",
    "이전 예에서는 단일 입력(형상 `(764,)`의 텐서)과 단일 출력(형상 `(10,)`의 예측 텐서)이 있는 모델을 고려했습니다. 그렇다면 입력 또는 출력이 여러 개인 모델은 어떨까요?\n",
    "\n",
    "shape `(32, 32, 3)` ( `(height, width, channels)` 입력과 shape `(None, 10)` 의 시계열 입력 `(timesteps, features)` 하십시오. 우리의 모델은이 입력들의 조합으로부터 계산 된 두 개의 출력을 가질 것입니다 : \"점수\"(모양 `(1,)` )와 5 개의 클래스 (모양 `(5,)` )에 대한 확률 분포."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 10)\n",
      "(2, 3, 4)\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "timeseries_input = tf.constant(np.arange(2*6*10).reshape(2,6,10), dtype='float32')\n",
    "print(timeseries_input.shape)\n",
    "x2 = layers.Conv1D(4, 4)(timeseries_input)  # (2,6,10)(4,10,4)\n",
    "print(x2.shape)\n",
    "x2 = layers.GlobalMaxPooling1D()(x2)        # (2,3,4)\n",
    "print(x2.shape)                             # (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:43.798671Z",
     "iopub.status.busy": "2021-04-07T17:59:43.797137Z",
     "iopub.status.idle": "2021-04-07T17:59:43.836889Z",
     "shell.execute_reply": "2021-04-07T17:59:43.837258Z"
    },
    "id": "5f958449a057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " img_input (InputLayer)         [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " ts_input (InputLayer)          [(None, None, 10)]   0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 30, 30, 3)    84          ['img_input[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, None, 3)      93          ['ts_input[0][0]']               \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Global  (None, 3)           0           ['conv2d_1[0][0]']               \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 3)           0           ['conv1d_1[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 6)            0           ['global_max_pooling2d_1[0][0]', \n",
      "                                                                  'global_max_pooling1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " score_output (Dense)           (None, 1)            7           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " class_output (Dense)           (None, 5)            35          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 219\n",
      "Trainable params: 219\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_input = keras.Input(shape=(32, 32, 3), name=\"img_input\")     # (None,32,32,3)\n",
    "timeseries_input = keras.Input(shape=(None, 10), name=\"ts_input\")  # (None,None,10)\n",
    "\n",
    "x1 = layers.Conv2D(3, 3)(image_input)       # (None,32,32,3)(3,3,3,3)\n",
    "x1 = layers.GlobalMaxPooling2D()(x1)        # (None,30,30,3)\n",
    "                                            # (None,3)\n",
    "\n",
    "x2 = layers.Conv1D(3, 3)(timeseries_input)  # (None,None,10)(3,10,3)\n",
    "x2 = layers.GlobalMaxPooling1D()(x2)        # (None,None,3)\n",
    "                                            # (None,3)\n",
    "\n",
    "x = layers.concatenate([x1, x2])            # (None,6)\n",
    " \n",
    "score_output = layers.Dense(1, name=\"score_output\")(x)  # (None,6)(6,1) => (None,1)\n",
    "class_output = layers.Dense(5, name=\"class_output\")(x)  # (None,6)(6,5) => (None,5)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[image_input, timeseries_input], outputs=[score_output, class_output]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, \"my_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df3ed34fe78b"
   },
   "source": [
    "이 모델을 플로팅하여 여기서 수행중인 작업을 명확하게 확인할 수 있습니다 (플롯에 표시된 셰이프는 샘플 별 셰이프가 아니라 배치 셰이프 임)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:43.841632Z",
     "iopub.status.busy": "2021-04-07T17:59:43.840966Z",
     "iopub.status.idle": "2021-04-07T17:59:43.997553Z",
     "shell.execute_reply": "2021-04-07T17:59:43.997939Z"
    },
    "id": "ac8c1baca9e3"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d979e89b335"
   },
   "source": [
    "컴파일 타임에 손실 함수를 목록으로 전달하여 출력마다 다른 손실을 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.008729Z",
     "iopub.status.busy": "2021-04-07T17:59:44.008083Z",
     "iopub.status.idle": "2021-04-07T17:59:44.020566Z",
     "shell.execute_reply": "2021-04-07T17:59:44.020024Z"
    },
    "id": "9655c0084d70"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5fc73405283"
   },
   "source": [
    "모델에 단일 손실 함수만 전달하는 경우, 모든 출력에 동일한 손실 함수가 적용됩니다(여기서는 적합하지 않음).\n",
    "\n",
    "메트릭의 경우도 마찬가지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.031233Z",
     "iopub.status.busy": "2021-04-07T17:59:44.030430Z",
     "iopub.status.idle": "2021-04-07T17:59:44.054558Z",
     "shell.execute_reply": "2021-04-07T17:59:44.054914Z"
    },
    "id": "b4c0c6c564bc"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    "    metrics=[\n",
    "        [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        [keras.metrics.CategoricalAccuracy()],\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dd9fb0343cc"
   },
   "source": [
    "출력 레이어에 이름을 지정 했으므로 dict를 통해 출력 당 손실 및 메트릭을 지정할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.064527Z",
     "iopub.status.busy": "2021-04-07T17:59:44.063850Z",
     "iopub.status.idle": "2021-04-07T17:59:44.083742Z",
     "shell.execute_reply": "2021-04-07T17:59:44.083134Z"
    },
    "id": "42cb75110fc3"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfd95ac0dd8b"
   },
   "source": [
    "출력이 두 개 이상인 경우 명시적 이름과 사전을 사용하는 것이 좋습니다.\n",
    "\n",
    "`loss_weights` 인수를 사용하여 출력별 손실에 서로 다른 가중치를 부여할 수 있습니다(예를 들어, 클래스 손실에 2x의 중요도를 부여하여 이 예에서 \"score\" 손실에 우선권을 줄 수 있음)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.093695Z",
     "iopub.status.busy": "2021-04-07T17:59:44.093100Z",
     "iopub.status.idle": "2021-04-07T17:59:44.112359Z",
     "shell.execute_reply": "2021-04-07T17:59:44.112739Z"
    },
    "id": "23a71e5f5227"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    "    loss_weights={\"score_output\": 2.0, \"class_output\": 1.0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "367f598029e7"
   },
   "source": [
    "이러한 출력이 예측 용이지만 훈련 용이 아닌 경우 특정 출력에 대한 손실을 계산하지 않도록 선택할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.121160Z",
     "iopub.status.busy": "2021-04-07T17:59:44.120554Z",
     "iopub.status.idle": "2021-04-07T17:59:44.130318Z",
     "shell.execute_reply": "2021-04-07T17:59:44.130734Z"
    },
    "id": "6d51aa372ef4"
   },
   "outputs": [],
   "source": [
    "# List loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[None, keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Or dict loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\"class_output\": keras.losses.CategoricalCrossentropy()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8314a8b3a7c7"
   },
   "source": [
    "적합하게 다중 입력 또는 다중 출력 모델에 데이터를 전달하는 것은 컴파일에서 손실 함수를 지정하는 것과 유사한 방식으로 작동합니다. **NumPy 배열 목록을** 전달할 수 있습니다 (손실 함수를 수신 한 출력에 1 : 1 매핑). **출력 이름을 NumPy 배열에 매핑합니다** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.135391Z",
     "iopub.status.busy": "2021-04-07T17:59:44.134811Z",
     "iopub.status.idle": "2021-04-07T17:59:46.741893Z",
     "shell.execute_reply": "2021-04-07T17:59:46.742292Z"
    },
    "id": "0539da84328b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step - loss: 29.1732 - score_output_loss: 6.0338 - class_output_loss: 23.1394\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 27.5324 - score_output_loss: 4.5202 - class_output_loss: 23.0122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20bf6759f10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Generate dummy NumPy data\n",
    "img_data = np.random.random_sample(size=(100, 32, 32, 3))\n",
    "ts_data = np.random.random_sample(size=(100, 20, 10))\n",
    "score_targets = np.random.random_sample(size=(100, 1))\n",
    "class_targets = np.random.random_sample(size=(100, 5))\n",
    "\n",
    "# Fit on lists\n",
    "model.fit([img_data, ts_data], [score_targets, class_targets], batch_size=32, epochs=1)\n",
    "\n",
    "# Alternatively, fit on dicts\n",
    "model.fit(\n",
    "    {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "    {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e53eda8e1399"
   },
   "source": [
    "`Dataset` 사용 사례는 다음과 같습니다. NumPy 배열에서 수행 한 것과 유사하게 `Dataset` 은 튜플 튜플을 반환해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:46.752664Z",
     "iopub.status.busy": "2021-04-07T17:59:46.752034Z",
     "iopub.status.idle": "2021-04-07T17:59:47.185670Z",
     "shell.execute_reply": "2021-04-07T17:59:47.186035Z"
    },
    "id": "4df41a12ed2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 26.7783 - score_output_loss: 3.7902 - class_output_loss: 22.9881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20bf56bf190>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "        {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    )\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38ebf30ce6ac"
   },
   "source": [
    "## 콜백 사용하기\n",
    "\n",
    "Keras의 콜백은 훈련 중 다른 시점(epoch의 시작, 배치의 끝, epoch의 끝 등)에서 호출되며 다음과 같은 동작을 구현하는 데 사용할 수 있는 객체입니다.\n",
    "\n",
    "- 훈련 중 서로 다른 시점에서 유효성 검사 수행(내장된 epoch당 유효성 검사에서 더욱 확장)\n",
    "- 정기적으로 또는 특정 정확도 임계값을 초과할 때 모델 검사점 설정\n",
    "- 훈련이 정체 된 것처럼 보일 때 모델의 학습 속도 변경\n",
    "- 훈련이 정체 된 것처럼 보일 때 최상위 레이어의 미세 조정\n",
    "- 교육이 종료되거나 특정 성능 임계 값을 초과 한 경우 전자 메일 또는 인스턴트 메시지 알림 보내기\n",
    "- 기타\n",
    "\n",
    "콜백은 `fit()` 에 대한 호출에 목록으로 전달 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:47.193545Z",
     "iopub.status.busy": "2021-04-07T17:59:47.192522Z",
     "iopub.status.idle": "2021-04-07T17:59:57.855887Z",
     "shell.execute_reply": "2021-04-07T17:59:57.855277Z"
    },
    "id": "15036ddbee42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.3670 - sparse_categorical_accuracy: 0.8986 - val_loss: 0.2315 - val_sparse_categorical_accuracy: 0.9302\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 1s 967us/step - loss: 0.1739 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.1789 - val_sparse_categorical_accuracy: 0.9471\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 1s 967us/step - loss: 0.1253 - sparse_categorical_accuracy: 0.9619 - val_loss: 0.1584 - val_sparse_categorical_accuracy: 0.9539\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 1s 934us/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9704 - val_loss: 0.1613 - val_sparse_categorical_accuracy: 0.9528\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 1s 945us/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9749 - val_loss: 0.1489 - val_sparse_categorical_accuracy: 0.9608\n",
      "Epoch 5: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b87f16970>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "303815509732"
   },
   "source": [
    "### 많은 내장 콜백을 사용할 수 있습니다\n",
    "\n",
    "- `ModelCheckpoint` : 주기적으로 모델을 저장합니다.\n",
    "- `EarlyStopping`: 훈련이 더 이상 유효성 검사 메트릭을 개선하지 못하는 경우 훈련을 중단합니다.\n",
    "- `TensorBoard` : 시각화 할 수 있습니다 정기적으로 쓰기 모델 로그 [TensorBoard](https://www.tensorflow.org/tensorboard) (섹션 \"시각화\"에서 자세한 내용).\n",
    "- `CSVLogger` : 손실 및 메트릭 데이터를 CSV 파일로 스트리밍합니다.\n",
    "- 기타\n",
    "\n",
    "전체 목록은 [콜백 설명서](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/) 를 참조하십시오.\n",
    "\n",
    "### 자신의 콜백 작성\n",
    "\n",
    "기본 클래스 `keras.callbacks.Callback` 을 확장하여 사용자 정의 콜백을 작성할 수 있습니다. 콜백은 클래스 속성 `self.model` 통해 연관된 모델에 액세스 할 수 있습니다.\n",
    "\n",
    "[사용자 정의 콜백을 작성하기 위한 전체 가이드](https://www.tensorflow.org/guide/keras/custom_callback/)를 꼭 읽어보세요. 다음은 훈련 중 배치별 손실 값 목록을 저장하는 간단한 예입니다.\n",
    "\n",
    "다음은 훈련 중 배치 별 손실 값 목록을 저장하는 간단한 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:57.860674Z",
     "iopub.status.busy": "2021-04-07T17:59:57.860106Z",
     "iopub.status.idle": "2021-04-07T17:59:57.862542Z",
     "shell.execute_reply": "2021-04-07T17:59:57.862070Z"
    },
    "id": "b265d36ce608"
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ee672524987"
   },
   "source": [
    "## 모델 검사점 설정하기\n",
    "\n",
    "상대적으로 큰 데이터세트에 대한 모델을 훈련시킬 때는 모델의 검사점을 빈번하게 저장하는 것이 중요합니다.\n",
    "\n",
    "이를 수행하는 가장 쉬운 방법은 `ModelCheckpoint` 콜백을 사용하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:57.870033Z",
     "iopub.status.busy": "2021-04-07T17:59:57.868836Z",
     "iopub.status.idle": "2021-04-07T18:00:02.043065Z",
     "shell.execute_reply": "2021-04-07T18:00:02.042601Z"
    },
    "id": "83614be57725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3680 - sparse_categorical_accuracy: 0.8950\n",
      "Epoch 1: val_loss improved from inf to 0.22464, saving model to mymodel_1\n",
      "INFO:tensorflow:Assets written to: mymodel_1\\assets\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.3677 - sparse_categorical_accuracy: 0.8950 - val_loss: 0.2246 - val_sparse_categorical_accuracy: 0.9316\n",
      "Epoch 2/2\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1699 - sparse_categorical_accuracy: 0.9492\n",
      "Epoch 2: val_loss improved from 0.22464 to 0.18652, saving model to mymodel_2\n",
      "INFO:tensorflow:Assets written to: mymodel_2\\assets\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 0.1699 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.1865 - val_sparse_categorical_accuracy: 0.9421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b87ff9f70>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=\"mymodel_{epoch}\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f6afa36950c"
   },
   "source": [
    "`ModelCheckpoint` 콜백을 사용하여 내결함성을 구현할 수 있습니다. 훈련이 무작위로 중단 된 경우 모델의 마지막 저장된 상태에서 훈련을 다시 시작할 수있는 기능. 기본 예는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:02.050845Z",
     "iopub.status.busy": "2021-04-07T18:00:02.048933Z",
     "iopub.status.idle": "2021-04-07T18:00:11.144699Z",
     "shell.execute_reply": "2021-04-07T18:00:11.144180Z"
    },
    "id": "27ce92b2ad58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model\n",
      "  65/1563 [>.............................] - ETA: 1s - loss: 1.1217 - sparse_categorical_accuracy: 0.7038  INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.92\\assets\n",
      " 168/1563 [==>...........................] - ETA: 3s - loss: 0.7325 - sparse_categorical_accuracy: 0.8015INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.68\\assets\n",
      " 264/1563 [====>.........................] - ETA: 3s - loss: 0.6022 - sparse_categorical_accuracy: 0.8361INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.57\\assets\n",
      " 364/1563 [=====>........................] - ETA: 3s - loss: 0.5286 - sparse_categorical_accuracy: 0.8535INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.51\\assets\n",
      " 460/1563 [=======>......................] - ETA: 3s - loss: 0.4779 - sparse_categorical_accuracy: 0.8667INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.46\\assets\n",
      " 562/1563 [=========>....................] - ETA: 3s - loss: 0.4445 - sparse_categorical_accuracy: 0.8755INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.44\\assets\n",
      " 664/1563 [===========>..................] - ETA: 3s - loss: 0.4205 - sparse_categorical_accuracy: 0.8821INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.41\\assets\n",
      " 769/1563 [=============>................] - ETA: 2s - loss: 0.3972 - sparse_categorical_accuracy: 0.8879INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.39\\assets\n",
      " 861/1563 [===============>..............] - ETA: 2s - loss: 0.3797 - sparse_categorical_accuracy: 0.8925INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.37\\assets\n",
      " 957/1563 [=================>............] - ETA: 2s - loss: 0.3629 - sparse_categorical_accuracy: 0.8967INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.36\\assets\n",
      "1062/1563 [===================>..........] - ETA: 1s - loss: 0.3493 - sparse_categorical_accuracy: 0.9002INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.34\\assets\n",
      "1166/1563 [=====================>........] - ETA: 1s - loss: 0.3367 - sparse_categorical_accuracy: 0.9037INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.33\\assets\n",
      "1268/1563 [=======================>......] - ETA: 0s - loss: 0.3254 - sparse_categorical_accuracy: 0.9065INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.32\\assets\n",
      "1363/1563 [=========================>....] - ETA: 0s - loss: 0.3155 - sparse_categorical_accuracy: 0.9087INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.31\\assets\n",
      "1461/1563 [===========================>..] - ETA: 0s - loss: 0.3071 - sparse_categorical_accuracy: 0.9109INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.30\\assets\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2981 - sparse_categorical_accuracy: 0.9132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b89269310>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Prepare a directory to store all the checkpoints.\n",
    "checkpoint_dir = \"./ckpt\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "\n",
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()\n",
    "\n",
    "\n",
    "model = make_or_restore_model()\n",
    "callbacks = [\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the saved model name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + \"/ckpt-loss={loss:.2f}\", save_freq=100\n",
    "    )\n",
    "]\n",
    "model.fit(x_train, y_train, epochs=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da3ab58d5235"
   },
   "source": [
    "또한 모델 저장 및 복원을 위해 자체 콜백을 작성하십시오.\n",
    "\n",
    "직렬화 및 저장에 대한 전체 안내서는 [모델 저장 및 직렬화 안내서를](https://www.tensorflow.org/guide/keras/save_and_serialize/) 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9342cc2ddba"
   },
   "source": [
    "## 학습 속도 일정 사용하기\n",
    "\n",
    "딥 러닝 모델을 훈련 할 때 일반적인 패턴은 훈련이 진행됨에 따라 점차적으로 학습을 줄이는 것입니다. 이것을 일반적으로 \"학습률 감소\"라고합니다.\n",
    "\n",
    "학습 붕괴 스케줄은 정적 인 (현재 에포크 또는 현재 배치 인덱스의 함수로서 미리 고정됨) 또는 동적 (모델의 현재 행동, 특히 검증 손실에 대응) 일 수있다.\n",
    "\n",
    "### 옵티마이저로 일정 전달하기\n",
    "\n",
    "옵티 마이저에서 schedule 객체를 `learning_rate` 인수로 전달하여 정적 학습 속도 감소 스케줄을 쉽게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:11.150053Z",
     "iopub.status.busy": "2021-04-07T18:00:11.149381Z",
     "iopub.status.idle": "2021-04-07T18:00:11.151800Z",
     "shell.execute_reply": "2021-04-07T18:00:11.151244Z"
    },
    "id": "684f0ab6d3de"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_42556/2242243925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minitial_learning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0minitial_learning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.96\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstaircase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d742e44f535"
   },
   "source": [
    "`ExponentialDecay` , `PiecewiseConstantDecay` , `PolynomialDecay` 및 `InverseTimeDecay` 와 같은 몇 가지 기본 제공 일정을 사용할 수 있습니다.\n",
    "\n",
    "### 콜백을 사용하여 동적 학습 속도 일정 구현\n",
    "\n",
    "옵티마이저가 유효성 검사 메트릭에 액세스할 수 없으므로 이러한 일정 객체로는 동적 학습률 일정(예: 유효성 검사 손실이 더 이상 개선되지 않을 때 학습률 감소)을 달성할 수 없습니다.\n",
    "\n",
    "그러나 콜백은 유효성 검사 메트릭을 포함해 모든 메트릭에 액세스할 수 있습니다! 따라서 옵티마이저에서 현재 학습률을 수정하는 콜백을 사용하여 이 패턴을 달성할 수 있습니다. 실제로 이 부분이`ReduceLROnPlateau` 콜백으로 내장되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4a05f880175"
   },
   "source": [
    "## 훈련 중 손실 및 메트릭 시각화하기\n",
    "\n",
    "교육 중에 모델을 주시하는 가장 좋은 방법은 로컬에서 실행할 수있는 브라우저 기반 응용 프로그램 인 [TensorBoard](https://www.tensorflow.org/tensorboard) 를 사용하는 것입니다.\n",
    "\n",
    "- 교육 및 평가를위한 손실 및 지표의 라이브 플롯\n",
    "- (옵션) 레이어 활성화 히스토그램 시각화\n",
    "- (옵션) `Embedding` 레이어에서 학습한 포함된 공간의 3D 시각화\n",
    "\n",
    "pip와 함께 TensorFlow를 설치한 경우, 명령줄에서 TensorBoard를 시작할 수 있습니다.\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/full_path_to_your_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fcf386a1dad"
   },
   "source": [
    "### TensorBoard 콜백 사용하기\n",
    "\n",
    "TensorBoard를 Keras 모델 및 fit 메서드와 함께 사용하는 가장 쉬운 방법은 `TensorBoard` 콜백입니다.\n",
    "\n",
    "가장 간단한 경우로, 콜백에서 로그를 작성할 위치만 지정하면 바로 쓸 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:11.157400Z",
     "iopub.status.busy": "2021-04-07T18:00:11.156688Z",
     "iopub.status.idle": "2021-04-07T18:00:11.159760Z",
     "shell.execute_reply": "2021-04-07T18:00:11.159192Z"
    },
    "id": "f74247282ff6"
   },
   "outputs": [],
   "source": [
    "keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_logs\",\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    ")  # How often to write logs (default: once per epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50cd5f8631fd"
   },
   "source": [
    "자세한 내용 [`TensorBoard` 콜백 설명서](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/tensorboard/)를 참조하세요."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_and_evaluate.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
