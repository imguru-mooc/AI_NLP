{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPN9FwKMtr52"
   },
   "source": [
    "# Sequence to sequence learning for performing number addition\n",
    "\n",
    "**Author:** [Smerity](https://twitter.com/Smerity) and others<br>\n",
    "**Date created:** 2015/08/17<br>\n",
    "**Last modified:** 2020/04/17<br>\n",
    "**Description:** A model that learns to add strings of numbers, e.g. \"535+61\" -> \"596\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZxpnI4atr55"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this example, we train a model to learn to add two numbers, provided as strings.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- Input: \"535+61\"\n",
    "- Output: \"596\"\n",
    "\n",
    "Input may optionally be reversed, which was shown to increase performance in many tasks\n",
    " in: [Learning to Execute](http://arxiv.org/abs/1410.4615) and\n",
    "[Sequence to Sequence Learning with Neural Networks](\n",
    "\n",
    " http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n",
    "\n",
    "Theoretically, sequence order inversion introduces shorter term dependencies between\n",
    " source and target for this problem.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "For two digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits (reversed):\n",
    "\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlyRHbx-tr55"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6kXei3gOtr56"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "REVERSE = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T1vUFe4tr56"
   },
   "source": [
    "## Generate the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(list(\"0123456789\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(1, DIGITS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "f = lambda: int(\n",
    "    \"\".join(\n",
    "        np.random.choice(list(\"0123456789\")) for i in range(np.random.randint(1, DIGITS + 1))\n",
    "    )\n",
    ")\n",
    "print(f())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "id": "l8nyFVWltr57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '+': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11}\n",
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = \"0123456789+ \"\n",
    "ctable = CharacterTable(chars)\n",
    "print(ctable.char_indices)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "    a, b = f(), f()\n",
    "#     print(a,b)\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "#     print(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = \"{}+{}\".format(a, b)\n",
    "    query = q + \" \" * (MAXLEN - len(q))\n",
    "#     print(\"[%s]\"%query)\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
    "#     print(\"[%s]\"%ans)\n",
    "    \n",
    "    if REVERSE:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print(\"Total questions:\", len(questions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYSXv3brtr57"
   },
   "source": [
    "## Vectorize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n101qJ7Ztr57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jikim\\AppData\\Local\\Temp/ipykernel_2580/3022509869.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\jikim\\AppData\\Local\\Temp/ipykernel_2580/3022509869.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJ9dAmqwtr58"
   },
   "source": [
    "## Build the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "id": "Dtk6blRKtr58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 128)               72192     \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 4, 128)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 4, 128)            131584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4, 12)             1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNtII1lhtr59"
   },
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1fM9Tn2etr59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "1407/1407 [==============================] - 28s 17ms/step - loss: 1.7558 - accuracy: 0.3562 - val_loss: 1.5554 - val_accuracy: 0.4196\n",
      "Q 921+777 T 1698 ☒ 1726\n",
      "Q 3+432   T 435  ☒ 330 \n",
      "Q 964+606 T 1570 ☒ 1626\n",
      "Q 171+186 T 357  ☒ 777 \n",
      "Q 426+437 T 863  ☒ 707 \n",
      "Q 14+799  T 813  ☒ 701 \n",
      "Q 500+5   T 505  ☒ 151 \n",
      "Q 493+162 T 655  ☒ 777 \n",
      "Q 42+532  T 574  ☒ 455 \n",
      "Q 3+867   T 870  ☒ 781 \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.3465 - accuracy: 0.4976 - val_loss: 1.1741 - val_accuracy: 0.5649\n",
      "Q 182+54  T 236  ☒ 247 \n",
      "Q 775+776 T 1551 ☒ 1537\n",
      "Q 674+89  T 763  ☒ 737 \n",
      "Q 60+256  T 316  ☒ 307 \n",
      "Q 985+33  T 1018 ☒ 1037\n",
      "Q 433+32  T 465  ☒ 460 \n",
      "Q 970+29  T 999  ☒ 900 \n",
      "Q 74+295  T 369  ☒ 337 \n",
      "Q 181+94  T 275  ☒ 247 \n",
      "Q 459+564 T 1023 ☒ 1003\n",
      "\n",
      "Iteration 3\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.0489 - accuracy: 0.6119 - val_loss: 0.9407 - val_accuracy: 0.6611\n",
      "Q 42+802  T 844  ☑ 844 \n",
      "Q 35+402  T 437  ☒ 444 \n",
      "Q 218+920 T 1138 ☒ 1174\n",
      "Q 6+886   T 892  ☒ 884 \n",
      "Q 570+83  T 653  ☒ 663 \n",
      "Q 721+34  T 755  ☑ 755 \n",
      "Q 66+10   T 76   ☒ 66  \n",
      "Q 241+71  T 312  ☒ 314 \n",
      "Q 886+38  T 924  ☑ 924 \n",
      "Q 2+467   T 469  ☒ 474 \n",
      "\n",
      "Iteration 4\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.8678 - accuracy: 0.6819 - val_loss: 0.8154 - val_accuracy: 0.7030\n",
      "Q 387+404 T 791  ☒ 782 \n",
      "Q 236+904 T 1140 ☒ 1147\n",
      "Q 250+367 T 617  ☒ 610 \n",
      "Q 42+763  T 805  ☒ 800 \n",
      "Q 448+456 T 904  ☒ 900 \n",
      "Q 3+421   T 424  ☒ 426 \n",
      "Q 14+319  T 333  ☒ 342 \n",
      "Q 292+579 T 871  ☒ 863 \n",
      "Q 772+396 T 1168 ☒ 1163\n",
      "Q 693+22  T 715  ☑ 715 \n",
      "\n",
      "Iteration 5\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.7704 - accuracy: 0.7204 - val_loss: 0.7380 - val_accuracy: 0.7311\n",
      "Q 666+201 T 867  ☑ 867 \n",
      "Q 43+194  T 237  ☑ 237 \n",
      "Q 792+617 T 1409 ☒ 1408\n",
      "Q 346+22  T 368  ☒ 367 \n",
      "Q 278+64  T 342  ☒ 340 \n",
      "Q 420+54  T 474  ☒ 477 \n",
      "Q 805+10  T 815  ☑ 815 \n",
      "Q 993+1   T 994  ☒ 998 \n",
      "Q 73+28   T 101  ☒ 102 \n",
      "Q 231+19  T 250  ☒ 247 \n",
      "\n",
      "Iteration 6\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.7024 - accuracy: 0.7455 - val_loss: 0.6765 - val_accuracy: 0.7506\n",
      "Q 477+959 T 1436 ☒ 1432\n",
      "Q 178+10  T 188  ☒ 187 \n",
      "Q 6+69    T 75   ☒ 74  \n",
      "Q 63+769  T 832  ☒ 837 \n",
      "Q 468+72  T 540  ☒ 537 \n",
      "Q 105+9   T 114  ☒ 112 \n",
      "Q 946+9   T 955  ☒ 953 \n",
      "Q 41+985  T 1026 ☒ 1027\n",
      "Q 1+1     T 2    ☒ 1   \n",
      "Q 842+843 T 1685 ☒ 1682\n",
      "\n",
      "Iteration 7\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.5691 - accuracy: 0.7929 - val_loss: 0.4276 - val_accuracy: 0.8425\n",
      "Q 724+28  T 752  ☑ 752 \n",
      "Q 744+55  T 799  ☑ 799 \n",
      "Q 927+935 T 1862 ☑ 1862\n",
      "Q 2+33    T 35   ☑ 35  \n",
      "Q 575+582 T 1157 ☒ 1155\n",
      "Q 14+571  T 585  ☑ 585 \n",
      "Q 527+2   T 529  ☑ 529 \n",
      "Q 827+769 T 1596 ☒ 1694\n",
      "Q 83+403  T 486  ☒ 485 \n",
      "Q 471+66  T 537  ☒ 538 \n",
      "\n",
      "Iteration 8\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.2997 - accuracy: 0.9048 - val_loss: 0.2177 - val_accuracy: 0.9366\n",
      "Q 92+14   T 106  ☑ 106 \n",
      "Q 303+3   T 306  ☑ 306 \n",
      "Q 29+458  T 487  ☑ 487 \n",
      "Q 499+45  T 544  ☒ 543 \n",
      "Q 508+814 T 1322 ☒ 1323\n",
      "Q 618+106 T 724  ☑ 724 \n",
      "Q 217+57  T 274  ☑ 274 \n",
      "Q 281+5   T 286  ☑ 286 \n",
      "Q 49+579  T 628  ☒ 627 \n",
      "Q 99+527  T 626  ☑ 626 \n",
      "\n",
      "Iteration 9\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.1613 - accuracy: 0.9614 - val_loss: 0.1304 - val_accuracy: 0.9673\n",
      "Q 654+369 T 1023 ☑ 1023\n",
      "Q 560+39  T 599  ☒ 699 \n",
      "Q 768+968 T 1736 ☑ 1736\n",
      "Q 82+866  T 948  ☑ 948 \n",
      "Q 37+304  T 341  ☑ 341 \n",
      "Q 967+6   T 973  ☑ 973 \n",
      "Q 151+4   T 155  ☑ 155 \n",
      "Q 633+466 T 1099 ☒ 1199\n",
      "Q 610+709 T 1319 ☑ 1319\n",
      "Q 972+26  T 998  ☑ 998 \n",
      "\n",
      "Iteration 10\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.0932 - accuracy: 0.9794 - val_loss: 0.0818 - val_accuracy: 0.9801\n",
      "Q 935+25  T 960  ☑ 960 \n",
      "Q 15+935  T 950  ☑ 950 \n",
      "Q 65+585  T 650  ☑ 650 \n",
      "Q 616+9   T 625  ☑ 625 \n",
      "Q 728+949 T 1677 ☑ 1677\n",
      "Q 722+207 T 929  ☑ 929 \n",
      "Q 65+68   T 133  ☑ 133 \n",
      "Q 393+89  T 482  ☑ 482 \n",
      "Q 26+93   T 119  ☑ 119 \n",
      "Q 81+10   T 91   ☑ 91  \n",
      "\n",
      "Iteration 11\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0644 - accuracy: 0.9843 - val_loss: 0.0500 - val_accuracy: 0.9892\n",
      "Q 65+19   T 84   ☑ 84  \n",
      "Q 302+77  T 379  ☑ 379 \n",
      "Q 869+719 T 1588 ☑ 1588\n",
      "Q 713+990 T 1703 ☑ 1703\n",
      "Q 28+262  T 290  ☑ 290 \n",
      "Q 96+43   T 139  ☑ 139 \n",
      "Q 64+144  T 208  ☑ 208 \n",
      "Q 53+32   T 85   ☑ 85  \n",
      "Q 749+322 T 1071 ☑ 1071\n",
      "Q 41+136  T 177  ☑ 177 \n",
      "\n",
      "Iteration 12\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0544 - accuracy: 0.9863 - val_loss: 0.0416 - val_accuracy: 0.9901\n",
      "Q 93+401  T 494  ☑ 494 \n",
      "Q 21+628  T 649  ☑ 649 \n",
      "Q 12+418  T 430  ☒ 420 \n",
      "Q 94+470  T 564  ☑ 564 \n",
      "Q 89+321  T 410  ☑ 410 \n",
      "Q 151+4   T 155  ☑ 155 \n",
      "Q 675+54  T 729  ☑ 729 \n",
      "Q 213+83  T 296  ☑ 296 \n",
      "Q 159+7   T 166  ☑ 166 \n",
      "Q 145+17  T 162  ☑ 162 \n",
      "\n",
      "Iteration 13\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 0.0652 - val_accuracy: 0.9792\n",
      "Q 513+48  T 561  ☑ 561 \n",
      "Q 0+157   T 157  ☒ 158 \n",
      "Q 768+97  T 865  ☑ 865 \n",
      "Q 633+50  T 683  ☑ 683 \n",
      "Q 27+45   T 72   ☑ 72  \n",
      "Q 432+151 T 583  ☑ 583 \n",
      "Q 190+3   T 193  ☑ 193 \n",
      "Q 959+189 T 1148 ☑ 1148\n",
      "Q 800+390 T 1190 ☑ 1190\n",
      "Q 306+69  T 375  ☑ 375 \n",
      "\n",
      "Iteration 14\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.0375 - accuracy: 0.9906 - val_loss: 0.0173 - val_accuracy: 0.9969\n",
      "Q 501+929 T 1430 ☑ 1430\n",
      "Q 10+218  T 228  ☑ 228 \n",
      "Q 415+843 T 1258 ☑ 1258\n",
      "Q 28+596  T 624  ☑ 624 \n",
      "Q 54+692  T 746  ☑ 746 \n",
      "Q 9+375   T 384  ☑ 384 \n",
      "Q 15+883  T 898  ☑ 898 \n",
      "Q 637+52  T 689  ☑ 689 \n",
      "Q 265+11  T 276  ☑ 276 \n",
      "Q 3+196   T 199  ☑ 199 \n",
      "\n",
      "Iteration 15\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.0345 - accuracy: 0.9904 - val_loss: 0.0145 - val_accuracy: 0.9972\n",
      "Q 0+924   T 924  ☑ 924 \n",
      "Q 563+537 T 1100 ☒ 1000\n",
      "Q 614+33  T 647  ☑ 647 \n",
      "Q 879+62  T 941  ☑ 941 \n",
      "Q 41+97   T 138  ☑ 138 \n",
      "Q 71+109  T 180  ☒ 170 \n",
      "Q 249+45  T 294  ☑ 294 \n",
      "Q 471+837 T 1308 ☑ 1308\n",
      "Q 13+371  T 384  ☑ 384 \n",
      "Q 17+611  T 628  ☑ 628 \n",
      "\n",
      "Iteration 16\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0258 - accuracy: 0.9934 - val_loss: 0.0222 - val_accuracy: 0.9945\n",
      "Q 367+755 T 1122 ☑ 1122\n",
      "Q 937+66  T 1003 ☑ 1003\n",
      "Q 158+82  T 240  ☑ 240 \n",
      "Q 45+832  T 877  ☑ 877 \n",
      "Q 76+266  T 342  ☑ 342 \n",
      "Q 5+146   T 151  ☑ 151 \n",
      "Q 756+45  T 801  ☑ 801 \n",
      "Q 51+554  T 605  ☑ 605 \n",
      "Q 484+241 T 725  ☑ 725 \n",
      "Q 139+77  T 216  ☑ 216 \n",
      "\n",
      "Iteration 17\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0333 - accuracy: 0.9904 - val_loss: 0.0173 - val_accuracy: 0.9956\n",
      "Q 86+616  T 702  ☑ 702 \n",
      "Q 641+95  T 736  ☑ 736 \n",
      "Q 45+792  T 837  ☑ 837 \n",
      "Q 962+570 T 1532 ☑ 1532\n",
      "Q 415+6   T 421  ☑ 421 \n",
      "Q 85+410  T 495  ☑ 495 \n",
      "Q 643+4   T 647  ☑ 647 \n",
      "Q 807+741 T 1548 ☑ 1548\n",
      "Q 8+31    T 39   ☒ 49  \n",
      "Q 0+106   T 106  ☑ 106 \n",
      "\n",
      "Iteration 18\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0256 - accuracy: 0.9932 - val_loss: 0.0346 - val_accuracy: 0.9887\n",
      "Q 527+0   T 527  ☑ 527 \n",
      "Q 6+141   T 147  ☑ 147 \n",
      "Q 13+318  T 331  ☑ 331 \n",
      "Q 6+16    T 22   ☑ 22  \n",
      "Q 15+664  T 679  ☑ 679 \n",
      "Q 108+25  T 133  ☑ 133 \n",
      "Q 80+631  T 711  ☑ 711 \n",
      "Q 977+653 T 1630 ☑ 1630\n",
      "Q 949+3   T 952  ☑ 952 \n",
      "Q 98+782  T 880  ☑ 880 \n",
      "\n",
      "Iteration 19\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.0132 - val_accuracy: 0.9970\n",
      "Q 499+72  T 571  ☑ 571 \n",
      "Q 5+214   T 219  ☑ 219 \n",
      "Q 705+40  T 745  ☑ 745 \n",
      "Q 398+23  T 421  ☑ 421 \n",
      "Q 42+76   T 118  ☑ 118 \n",
      "Q 87+61   T 148  ☑ 148 \n",
      "Q 885+835 T 1720 ☑ 1720\n",
      "Q 822+1   T 823  ☑ 823 \n",
      "Q 68+863  T 931  ☑ 931 \n",
      "Q 90+599  T 689  ☑ 689 \n",
      "\n",
      "Iteration 20\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0160 - val_accuracy: 0.9956\n",
      "Q 315+44  T 359  ☑ 359 \n",
      "Q 729+52  T 781  ☑ 781 \n",
      "Q 69+448  T 517  ☑ 517 \n",
      "Q 856+93  T 949  ☑ 949 \n",
      "Q 924+359 T 1283 ☑ 1283\n",
      "Q 647+891 T 1538 ☑ 1538\n",
      "Q 836+966 T 1802 ☑ 1802\n",
      "Q 960+261 T 1221 ☑ 1221\n",
      "Q 806+36  T 842  ☑ 842 \n",
      "Q 145+41  T 186  ☑ 186 \n",
      "\n",
      "Iteration 21\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.0271 - accuracy: 0.9931 - val_loss: 0.0102 - val_accuracy: 0.9976\n",
      "Q 38+564  T 602  ☑ 602 \n",
      "Q 820+57  T 877  ☑ 877 \n",
      "Q 44+55   T 99   ☑ 99  \n",
      "Q 354+3   T 357  ☑ 357 \n",
      "Q 98+967  T 1065 ☑ 1065\n",
      "Q 795+7   T 802  ☑ 802 \n",
      "Q 59+67   T 126  ☑ 126 \n",
      "Q 889+724 T 1613 ☑ 1613\n",
      "Q 633+307 T 940  ☑ 940 \n",
      "Q 7+937   T 944  ☑ 944 \n",
      "\n",
      "Iteration 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0163 - accuracy: 0.9955 - val_loss: 0.0166 - val_accuracy: 0.9958\n",
      "Q 398+601 T 999  ☒ 199 \n",
      "Q 715+785 T 1500 ☑ 1500\n",
      "Q 159+903 T 1062 ☑ 1062\n",
      "Q 851+77  T 928  ☑ 928 \n",
      "Q 325+24  T 349  ☑ 349 \n",
      "Q 197+423 T 620  ☒ 610 \n",
      "Q 590+65  T 655  ☑ 655 \n",
      "Q 149+3   T 152  ☑ 152 \n",
      "Q 93+306  T 399  ☑ 399 \n",
      "Q 967+6   T 973  ☑ 973 \n",
      "\n",
      "Iteration 23\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.0314 - val_accuracy: 0.9903\n",
      "Q 160+181 T 341  ☑ 341 \n",
      "Q 82+391  T 473  ☑ 473 \n",
      "Q 166+423 T 589  ☑ 589 \n",
      "Q 924+19  T 943  ☑ 943 \n",
      "Q 29+668  T 697  ☑ 697 \n",
      "Q 53+603  T 656  ☒ 657 \n",
      "Q 188+39  T 227  ☑ 227 \n",
      "Q 653+4   T 657  ☑ 657 \n",
      "Q 86+640  T 726  ☑ 726 \n",
      "Q 15+200  T 215  ☑ 215 \n",
      "\n",
      "Iteration 24\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0125 - val_accuracy: 0.9965\n",
      "Q 997+57  T 1054 ☑ 1054\n",
      "Q 620+96  T 716  ☑ 716 \n",
      "Q 885+54  T 939  ☑ 939 \n",
      "Q 730+819 T 1549 ☑ 1549\n",
      "Q 25+318  T 343  ☑ 343 \n",
      "Q 16+265  T 281  ☑ 281 \n",
      "Q 35+160  T 195  ☑ 195 \n",
      "Q 2+344   T 346  ☑ 346 \n",
      "Q 7+743   T 750  ☑ 750 \n",
      "Q 740+29  T 769  ☑ 769 \n",
      "\n",
      "Iteration 25\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Q 636+641 T 1277 ☑ 1277\n",
      "Q 591+34  T 625  ☑ 625 \n",
      "Q 501+31  T 532  ☑ 532 \n",
      "Q 38+524  T 562  ☑ 562 \n",
      "Q 442+52  T 494  ☑ 494 \n",
      "Q 806+36  T 842  ☑ 842 \n",
      "Q 19+56   T 75   ☑ 75  \n",
      "Q 20+436  T 456  ☑ 456 \n",
      "Q 87+220  T 307  ☑ 307 \n",
      "Q 785+438 T 1223 ☑ 1223\n",
      "\n",
      "Iteration 26\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Q 11+321  T 332  ☑ 332 \n",
      "Q 628+311 T 939  ☑ 939 \n",
      "Q 32+453  T 485  ☑ 485 \n",
      "Q 870+858 T 1728 ☑ 1728\n",
      "Q 92+348  T 440  ☑ 440 \n",
      "Q 30+62   T 92   ☑ 92  \n",
      "Q 858+77  T 935  ☑ 935 \n",
      "Q 674+9   T 683  ☑ 683 \n",
      "Q 29+771  T 800  ☑ 800 \n",
      "Q 75+810  T 885  ☑ 885 \n",
      "\n",
      "Iteration 27\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 0.0054 - val_accuracy: 0.9990\n",
      "Q 873+26  T 899  ☑ 899 \n",
      "Q 38+11   T 49   ☑ 49  \n",
      "Q 8+105   T 113  ☑ 113 \n",
      "Q 443+272 T 715  ☑ 715 \n",
      "Q 89+181  T 270  ☑ 270 \n",
      "Q 984+82  T 1066 ☑ 1066\n",
      "Q 315+9   T 324  ☑ 324 \n",
      "Q 13+275  T 288  ☑ 288 \n",
      "Q 701+780 T 1481 ☑ 1481\n",
      "Q 15+485  T 500  ☑ 500 \n",
      "\n",
      "Iteration 28\n",
      "1407/1407 [==============================] - 23s 17ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.0059 - val_accuracy: 0.9989\n",
      "Q 522+581 T 1103 ☑ 1103\n",
      "Q 633+307 T 940  ☑ 940 \n",
      "Q 0+212   T 212  ☑ 212 \n",
      "Q 610+31  T 641  ☑ 641 \n",
      "Q 1+234   T 235  ☑ 235 \n",
      "Q 336+35  T 371  ☑ 371 \n",
      "Q 775+309 T 1084 ☑ 1084\n",
      "Q 16+621  T 637  ☑ 637 \n",
      "Q 36+44   T 80   ☑ 80  \n",
      "Q 607+0   T 607  ☑ 607 \n",
      "\n",
      "Iteration 29\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0330 - val_accuracy: 0.9893\n",
      "Q 27+647  T 674  ☑ 674 \n",
      "Q 185+313 T 498  ☑ 498 \n",
      "Q 132+1   T 133  ☑ 133 \n",
      "Q 52+27   T 79   ☑ 79  \n",
      "Q 45+91   T 136  ☑ 136 \n",
      "Q 661+78  T 739  ☑ 739 \n",
      "Q 43+129  T 172  ☑ 172 \n",
      "Q 915+83  T 998  ☑ 998 \n",
      "Q 872+72  T 944  ☑ 944 \n",
      "Q 172+97  T 269  ☑ 269 \n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"☑ \" + guess)\n",
    "        else:\n",
    "            print(\"☒ \" + guess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3mUreeotr59"
   },
   "source": [
    "You'll get to 99+% validation accuracy after ~30 epochs.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "addition_rnn",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
