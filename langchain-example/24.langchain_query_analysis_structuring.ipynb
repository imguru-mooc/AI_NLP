{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 랭체인(LangChain) Query Analysis Structuring 예제\n",
        "## 작성자 : AISchool ( http://aischool.ai/%ec%98%a8%eb%9d%bc%ec%9d%b8-%ea%b0%95%ec%9d%98-%ec%b9%b4%ed%85%8c%ea%b3%a0%eb%a6%ac/ )\n",
        "## Reference : https://python.langchain.com/docs/use_cases/query_analysis/techniques/structuring/"
      ],
      "metadata": {
        "id": "dR6gqM5aJ2YB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "검색 및 필터링 매개변수로 텍스트 입력을 전환하는 것은 검색에서 가장 중요한 단계 중 하나입니다. **비구조화된 입력에서 구조화된 매개변수를 추출하는 이 과정을 우리는 '쿼리 구조화(query structuring)'**라고 합니다.\n",
        "\n",
        "이를 설명하기 위해, Quickstart 예제에서 살펴본 LangChain YouTube 비디오에 대한 Q&A 봇의 예시로 돌아가서, 이 경우에 있어 더 복잡한 구조화된 쿼리가 어떻게 보일지 살펴보겠습니다."
      ],
      "metadata": {
        "id": "pLMgL-HrZr3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 설치"
      ],
      "metadata": {
        "id": "8dFf1LyAalCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain langchain-openai youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QpupPqmjThV",
        "outputId": "f9c7a6c5-7ab8-4fce-f5a5-59767455af66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.1/289.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI API Key 설정"
      ],
      "metadata": {
        "id": "2J_c-XcBVGSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_KEY = \"여러분의_OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "Te8R0rpGv8zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load example document"
      ],
      "metadata": {
        "id": "9cA5jaqFk5HP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "실습을 위해 YouTube에서 문서들을 불러옵니다."
      ],
      "metadata": {
        "id": "pzdEbnQqbGR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import YoutubeLoader\n",
        "\n",
        "urls = [\n",
        "    \"https://www.youtube.com/watch?v=HAn9vnJy6S4\",\n",
        "    \"https://www.youtube.com/watch?v=dA1cHGACXCo\",\n",
        "    \"https://www.youtube.com/watch?v=ZcEMLz27sL4\",\n",
        "    \"https://www.youtube.com/watch?v=hvAPnpSfSGo\",\n",
        "    \"https://www.youtube.com/watch?v=EhlPDL4QrWY\",\n",
        "    \"https://www.youtube.com/watch?v=mmBo8nlu2j0\",\n",
        "    \"https://www.youtube.com/watch?v=rQdibOsL1ps\",\n",
        "    \"https://www.youtube.com/watch?v=28lC4fqukoc\",\n",
        "    \"https://www.youtube.com/watch?v=es-9MgxB-uc\",\n",
        "    \"https://www.youtube.com/watch?v=wLRHwKuKvOE\",\n",
        "    \"https://www.youtube.com/watch?v=ObIltMaRJvY\",\n",
        "    \"https://www.youtube.com/watch?v=DjuXACWYkkU\",\n",
        "    \"https://www.youtube.com/watch?v=o7C9ld6Ln-M\",\n",
        "]\n",
        "docs = []\n",
        "for url in urls:\n",
        "    docs.extend(YoutubeLoader.from_youtube_url(url, add_video_info=True).load())"
      ],
      "metadata": {
        "id": "Yur7We8rk6we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfLEhrask6ti",
        "outputId": "682be652-9c50-4df1-a496-53624a522022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'HAn9vnJy6S4',\n",
              " 'title': 'OpenGPTs',\n",
              " 'description': 'Unknown',\n",
              " 'view_count': 8217,\n",
              " 'thumbnail_url': 'https://i.ytimg.com/vi/HAn9vnJy6S4/hq720.jpg',\n",
              " 'publish_date': '2024-01-31 00:00:00',\n",
              " 'length': 1530,\n",
              " 'author': 'LangChain'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].page_content[:500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "eZfsKapYmMDP",
        "outputId": "45fceb36-defe-4e65-deb1-3fab9f1e73bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"hello today I want to talk about open gpts open gpts is a project that we built here at linkchain uh that replicates the GPT store in a few ways so it creates uh end user-facing friendly interface to create different Bots and these Bots can have access to different tools and they can uh be given files to retrieve things over and basically it's a way to create a variety of bots and expose the configuration of these Bots to end users it's all open source um it can be used with open AI it can be us\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query schema"
      ],
      "metadata": {
        "id": "_bXcvvx89iHq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "구조화된 쿼리를 생성하기 위해 먼저 우리는 쿼리 스키마를 정의할 필요가 있습니다. 각 문서가 제목, 조회수, 발행 날짜, 그리고 초 단위 길이를 가지고 있음을 알 수 있습니다. 우리는 **각 문서의 내용과 제목에 대해 비구조화된 검색을 수행하고 조회수, 발행 날짜, 비디오 길이에 대해 범위 필터링을 사용할 수 있는 인덱스를 구축**했다고 가정합시다.\n",
        "\n",
        "시작으로, **조회수, 발행 날짜, 비디오 길이에 대해 필터링할 수 있도록 명시적인 최소값과 최대값 속성을 가진 스키마**를 만들겠습니다. 그리고 우리는 **대본 내용과 비디오 제목에 대한 검색을 위해 별도의 속성을 추가**할 것입니다.\n",
        "\n",
        "**대안적으로, 각 필터링 가능한 필드에 하나 이상의 필터 속성 대신 (속성, 조건, 값) 튜플의 목록을 취하는 단일 필터 속성을 가진 보다 일반적인 스키마**를 생성할 수 있습니다. 이것을 어떻게 하는지도 보여드리겠습니다. **어떤 접근 방식이 가장 적합한지는 인덱스의 복잡성에 따라 다릅니다.** 필터링 가능한 필드가 많다면 단일 필터 쿼리 속성을 가지는 것이 더 낫습니다. 필터링 가능한 필드가 몇 개 없고/또는 매우 특정한 방식으로만 필터링 될 수 있는 필드가 있다면, 각각의 설명이 있는 별도의 쿼리 속성을 가지는 것이 유용할 수 있습니다."
      ],
      "metadata": {
        "id": "94LShWid91dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from typing import Literal, Optional, Tuple\n",
        "\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "\n",
        "class TutorialSearch(BaseModel):\n",
        "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
        "\n",
        "    content_search: str = Field(\n",
        "        ...,\n",
        "        description=\"Similarity search query applied to video transcripts.\",\n",
        "    )\n",
        "    title_search: str = Field(\n",
        "        ...,\n",
        "        description=(\n",
        "            \"Alternate version of the content search query to apply to video titles. \"\n",
        "            \"Should be succinct and only include key words that could be in a video \"\n",
        "            \"title.\"\n",
        "        ),\n",
        "    )\n",
        "    min_view_count: Optional[int] = Field(\n",
        "        None,\n",
        "        description=\"Minimum view count filter, inclusive. Only use if explicitly specified.\",\n",
        "    )\n",
        "    max_view_count: Optional[int] = Field(\n",
        "        None,\n",
        "        description=\"Maximum view count filter, exclusive. Only use if explicitly specified.\",\n",
        "    )\n",
        "    earliest_publish_date: Optional[datetime.date] = Field(\n",
        "        None,\n",
        "        description=\"Earliest publish date filter, inclusive. Only use if explicitly specified.\",\n",
        "    )\n",
        "    latest_publish_date: Optional[datetime.date] = Field(\n",
        "        None,\n",
        "        description=\"Latest publish date filter, exclusive. Only use if explicitly specified.\",\n",
        "    )\n",
        "    min_length_sec: Optional[int] = Field(\n",
        "        None,\n",
        "        description=\"Minimum video length in seconds, inclusive. Only use if explicitly specified.\",\n",
        "    )\n",
        "    max_length_sec: Optional[int] = Field(\n",
        "        None,\n",
        "        description=\"Maximum video length in seconds, exclusive. Only use if explicitly specified.\",\n",
        "    )\n",
        "\n",
        "    def pretty_print(self) -> None:\n",
        "        for field in self.__fields__:\n",
        "            if getattr(self, field) is not None and getattr(self, field) != getattr(\n",
        "                self.__fields__[field], \"default\", None\n",
        "            ):\n",
        "                print(f\"{field}: {getattr(self, field)}\")"
      ],
      "metadata": {
        "id": "Kn2wZ4-A9ht_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query generation"
      ],
      "metadata": {
        "id": "FDf6Ms0VCHEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용자 질문을 구조화된 쿼리로 변환하기 위해, 우리는 ChatOpenAI와 같은 **함수 호출 모델(function-calling model)**을 사용할 것입니다. LangChain에는 Pydantic 클래스를 통해 원하는 함수 호출 스키마를 쉽게 지정할 수 있는 몇 가지 좋은 생성자가 있습니다:"
      ],
      "metadata": {
        "id": "E31PXFf3DTn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
        "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
        "Given a question, return a database query optimized to retrieve the most relevant results.\n",
        "\n",
        "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, openai_api_key=OPENAI_KEY)\n",
        "structured_llm = llm.with_structured_output(TutorialSearch)\n",
        "query_analyzer = prompt | structured_llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIJSFB44-vGI",
        "outputId": "f1ccc862-7851-4764-91c3-e5e3703a0434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\n",
            "  warn_beta(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke({\"question\": \"rag from scratch\"}).pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DleCekdJ-vD8",
        "outputId": "d4cca425-54d4-4ec0-9310-dee3df3c8cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: rag from scratch\n",
            "title_search: rag from scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\"question\": \"videos on chat langchain published in 2023\"}\n",
        ").pretty_print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnco19lj-vBp",
        "outputId": "cdc6ea1e-ad4a-40af-f582-5546ba5cda39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: chat langchain\n",
            "title_search: chat langchain\n",
            "earliest_publish_date: 2023-01-01\n",
            "latest_publish_date: 2024-01-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\n",
        "        \"question\": \"how to use multi-modal models in an agent, only videos under 5 minutes\"\n",
        "    }\n",
        ").pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVwtPbCs-u-5",
        "outputId": "8eb2b870-d526-4d44-9bcb-b50dc255c058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: multi-modal models agent\n",
            "title_search: multi-modal models agent\n",
            "max_length_sec: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alternative: Succinct schema"
      ],
      "metadata": {
        "id": "_P6Lkva2HhSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "필터링 가능한 필드가 많은 경우, 자세한 스키마를 사용하면 성능에 악영향을 미칠 수 있으며, 함수 스키마의 크기 제한 때문에 실현이 불가능할 수도 있습니다. 이러한 경우에는 **명시성을 다소 희생하면서 간결성을 높인 쿼리 스키마(succinct query schemas)를 시도**할 수 있습니다:"
      ],
      "metadata": {
        "id": "9ms6AMvXJlG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Literal, Union\n",
        "\n",
        "\n",
        "class Filter(BaseModel):\n",
        "    field: Literal[\"view_count\", \"publish_date\", \"length_sec\"]\n",
        "    comparison: Literal[\"eq\", \"lt\", \"lte\", \"gt\", \"gte\"]\n",
        "    value: Union[int, datetime.date] = Field(\n",
        "        ...,\n",
        "        description=\"If field is publish_date then value must be a ISO-8601 format date\",\n",
        "    )\n",
        "\n",
        "\n",
        "class TutorialSearch(BaseModel):\n",
        "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
        "\n",
        "    content_search: str = Field(\n",
        "        ...,\n",
        "        description=\"Similarity search query applied to video transcripts.\",\n",
        "    )\n",
        "    title_search: str = Field(\n",
        "        ...,\n",
        "        description=(\n",
        "            \"Alternate version of the content search query to apply to video titles. \"\n",
        "            \"Should be succinct and only include key words that could be in a video \"\n",
        "            \"title.\"\n",
        "        ),\n",
        "    )\n",
        "    filters: List[Filter] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Filters over specific fields. Final condition is a logical conjunction of all filters.\",\n",
        "    )\n",
        "\n",
        "    def pretty_print(self) -> None:\n",
        "        for field in self.__fields__:\n",
        "            if getattr(self, field) is not None and getattr(self, field) != getattr(\n",
        "                self.__fields__[field], \"default\", None\n",
        "            ):\n",
        "                print(f\"{field}: {getattr(self, field)}\")"
      ],
      "metadata": {
        "id": "3LOS0rMM9hrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm = llm.with_structured_output(TutorialSearch)\n",
        "query_analyzer = prompt | structured_llm"
      ],
      "metadata": {
        "id": "CWwoJsSe9hod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke({\"question\": \"rag from scratch\"}).pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJjbI6Z1DdOr",
        "outputId": "27dc4325-f6f7-4f93-e6fc-5edb12fa7ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: rag from scratch\n",
            "title_search: rag\n",
            "filters: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\"question\": \"videos on chat langchain published in 2023\"}\n",
        ").pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FhXKAj0DdMd",
        "outputId": "4787d14c-c96e-4eac-a84c-697e8b7dbb33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: chat langchain\n",
            "title_search: 2023\n",
            "filters: [Filter(field='publish_date', comparison='eq', value=datetime.date(2023, 1, 1))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\n",
        "        \"question\": \"how to use multi-modal models in an agent, only videos under 5 minutes and with over 276 views\"\n",
        "    }\n",
        ").pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk6eBm9yDdKP",
        "outputId": "a3c31ef6-6d43-4231-8956-daf94cc76d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: multi-modal models in an agent\n",
            "title_search: multi-modal models\n",
            "filters: [Filter(field='length_sec', comparison='lt', value=300), Filter(field='view_count', comparison='gte', value=276)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "분석기가 **정수는 잘 처리하지만 날짜 범위에는 어려움을 겪는 것을 볼 수 있습니다. 이를 수정하기 위해 우리의 스키마 설명과/또는 프롬프트를 조정해볼 수 있습니다**:"
      ],
      "metadata": {
        "id": "wBYgV3nHLq2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TutorialSearch(BaseModel):\n",
        "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
        "\n",
        "    content_search: str = Field(\n",
        "        ...,\n",
        "        description=\"Similarity search query applied to video transcripts.\",\n",
        "    )\n",
        "    title_search: str = Field(\n",
        "        ...,\n",
        "        description=(\n",
        "            \"Alternate version of the content search query to apply to video titles. \"\n",
        "            \"Should be succinct and only include key words that could be in a video \"\n",
        "            \"title.\"\n",
        "        ),\n",
        "    )\n",
        "    filters: List[Filter] = Field(\n",
        "        default_factory=list,\n",
        "        description=(\n",
        "            \"Filters over specific fields. Final condition is a logical conjunction of all filters. \"\n",
        "            \"If a time period longer than one day is specified then it must result in filters that define a date range. \"\n",
        "            f\"Keep in mind the current date is {datetime.date.today().strftime('%m-%d-%Y')}.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    def pretty_print(self) -> None:\n",
        "        for field in self.__fields__:\n",
        "            if getattr(self, field) is not None and getattr(self, field) != getattr(\n",
        "                self.__fields__[field], \"default\", None\n",
        "            ):\n",
        "                print(f\"{field}: {getattr(self, field)}\")\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(TutorialSearch)\n",
        "query_analyzer = prompt | structured_llm"
      ],
      "metadata": {
        "id": "HJNtcsU3DdH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\"question\": \"videos on chat langchain published in 2023\"}\n",
        ").pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6jjCbveDdFc",
        "outputId": "7159c14c-722b-4b37-c7c2-ad9c2fd935d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: chat langchain\n",
            "title_search: chat langchain\n",
            "filters: [Filter(field='publish_date', comparison='gte', value=datetime.date(2023, 1, 1)), Filter(field='publish_date', comparison='lte', value=datetime.date(2023, 12, 31))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 방법이 효과가 있는 것 같습니다!"
      ],
      "metadata": {
        "id": "cw8RL1-sPNBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sorting: Going beyond search"
      ],
      "metadata": {
        "id": "RTf3tXbaP1HF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "특정 인덱스에서는 필드별 검색만이 결과를 검색하는 유일한 방법이 아닙니다 — 우리는 문서를 필드별로 정렬하고 상위 정렬 결과를 검색할 수도 있습니다. 구조화된 쿼리를 사용하면 **결과를 정렬하는 방법을 지정하는 별도의 쿼리 필드를 추가함으로써 이를 쉽게 수용**할 수 있습니다."
      ],
      "metadata": {
        "id": "fOGftQWfRDu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TutorialSearch(BaseModel):\n",
        "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
        "\n",
        "    content_search: str = Field(\n",
        "        \"\",\n",
        "        description=\"Similarity search query applied to video transcripts.\",\n",
        "    )\n",
        "    title_search: str = Field(\n",
        "        \"\",\n",
        "        description=(\n",
        "            \"Alternate version of the content search query to apply to video titles. \"\n",
        "            \"Should be succinct and only include key words that could be in a video \"\n",
        "            \"title.\"\n",
        "        ),\n",
        "    )\n",
        "    min_view_count: Optional[int] = Field(\n",
        "        None, description=\"Minimum view count filter, inclusive.\"\n",
        "    )\n",
        "    max_view_count: Optional[int] = Field(\n",
        "        None, description=\"Maximum view count filter, exclusive.\"\n",
        "    )\n",
        "    earliest_publish_date: Optional[datetime.date] = Field(\n",
        "        None, description=\"Earliest publish date filter, inclusive.\"\n",
        "    )\n",
        "    latest_publish_date: Optional[datetime.date] = Field(\n",
        "        None, description=\"Latest publish date filter, exclusive.\"\n",
        "    )\n",
        "    min_length_sec: Optional[int] = Field(\n",
        "        None, description=\"Minimum video length in seconds, inclusive.\"\n",
        "    )\n",
        "    max_length_sec: Optional[int] = Field(\n",
        "        None, description=\"Maximum video length in seconds, exclusive.\"\n",
        "    )\n",
        "    sort_by: Literal[\n",
        "        \"relevance\",\n",
        "        \"view_count\",\n",
        "        \"publish_date\",\n",
        "        \"length\",\n",
        "    ] = Field(\"relevance\", description=\"Attribute to sort by.\")\n",
        "    sort_order: Literal[\"ascending\", \"descending\"] = Field(\n",
        "        \"descending\", description=\"Whether to sort in ascending or descending order.\"\n",
        "    )\n",
        "\n",
        "    def pretty_print(self) -> None:\n",
        "        for field in self.__fields__:\n",
        "            if getattr(self, field) is not None and getattr(self, field) != getattr(\n",
        "                self.__fields__[field], \"default\", None\n",
        "            ):\n",
        "                print(f\"{field}: {getattr(self, field)}\")\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(TutorialSearch)\n",
        "query_analyzer = prompt | structured_llm"
      ],
      "metadata": {
        "id": "TvMh0pqARQri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\"question\": \"What has LangChain released lately?\"}\n",
        ").pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJJQj0KPRdcV",
        "outputId": "44839908-6f53-439b-f6bc-16659a71a1e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title_search: LangChain\n",
            "sort_by: publish_date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke({\"question\": \"What are the longest videos?\"}).pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CatWIFoSRdaK",
        "outputId": "abeca2e2-723a-4b7c-e226-6f7f7ab9e243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sort_by: length\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리는 검색과 정렬을 함께 지원할 수도 있습니다. 이는 **먼저 관련성 임계값 이상의 모든 결과를 검색한 다음 지정된 속성에 따라 그 결과들을 정렬하는 것**처럼 보일 수 있습니다:"
      ],
      "metadata": {
        "id": "BN9bpdOETKpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_analyzer.invoke(\n",
        "    {\"question\": \"What are the shortest videos about agents?\"}\n",
        ").pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zc7aAEIRdX9",
        "outputId": "04ea8c1f-4992-4ab2-d919-a4e2ea1615ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content_search: agents\n",
            "sort_by: length\n",
            "sort_order: ascending\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nc2aRCXET_pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMUQw0YgT_mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qv-ZpBeIRQpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJdRd5p9DdC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pBCdzZcUTWh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "piRIpxvhTWcX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}